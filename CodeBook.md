---
title: "Codebook"
author: "Rogerio Sarti Destro"
date: "Saturday, July 25, 2015"
output: html_document
---


### Purpose
This script was developed to take in the data generated by UC Irvine, with the purpose of training machine learning devices, and performs the requested operations listed bellow:

1) Merges the training and the test sets to create one data set.
2) Extracts only the measurements on the mean and standard deviation for each measurement. 
3) Uses descriptive activity names to name the activities in the data set
4) Appropriately labels the data set with descriptive variable names. 
5) From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

And generate a dataset.

### Data

The original data referred to measurements taken from individuals performing different activities with a smartphone attached to their waist, and consisted of accelerations, angular velocities, jerks, as well as some calculated values such as means and standard deviations.

The accelerations were divided in two:

* Total: Representing the accelerations measured with the smartphone's accelerometer
* Body: Calculated by subtracting the Gravity's acceleration from the total acceleration.

Both measurement's units are standard gravity's acceleration, also known as G.

The angular velocity in it's term was the measurment taken by the phone's gyroscope and has the unit of radians per second.

Each measurement was normalized and bounded between -1 and 1.

The data was divided in two main groups, or tables, in which each line represented a set of measurements for one individual in one condition. The training set contained 70% of it and the test set the remaining 30%. 

For each group there were another two tables containing the activity and the subject who performed it, each of which was arranged in a long column.

There were measurements in time and frequency domain, calculated with a FFT.

For more information on the original variables read the README.txt file found in the following link:
https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip



### Assumptions

During the script's four assumptions were made:

* The data was downloaded and extracted in a folder
* The strcture of the extrated folder was not altered
* The user will indicate the extracted folder's path
* The user has the plyr package installed

It was done this way in order to make this script generic, provided UCI uses the same standard for other data sets

### I/O

This scripts receives as input the path to the unzipped folder. 

E.g: "C:\\Users\\Rogerio\\Documents\\CursosOnline\\Coursera\\GettingData\\project\\getdata-projectfiles-UCI HAR Dataset"

And after the execution the script will generate a file called "tidyDataSet.txt" in the directory passed by the user.


## Workings
This section will explain each of the operations performed by the script in the following way:

* Line of the code

"Explanation"

### Header

* run_analysis <- function(directory = "C:\\Users\\Rogerio\\Documents\\CursosOnline\\Coursera\\GettingData\\project\\getdata-projectfiles-UCI HAR Dataset"){

"This script was developed as an R function, and named run_analysis as requested. The standard value adopted for directory was the path to the folder in which I was working. The \\ symbol shows that I wirk on a Windows machine"

### Preparing the data

* setwd(directory)

"This line was inserted to guarantee that the code will fetch and write the data in the folder specified by the user"

* Testset <- read.table(".\\test\\X_test.txt")

"This line reads the test set measurements into a variable"

* Trainset <- read.table(".\\train\\X_train.txt")

"This line reads the training set measurements into a variable"

* ActTrain <- read.table(".\\train\\y_train.txt")

"This line reads the training set's activity labels into a variable"

* ActTest <- read.table(".\\test\\y_test.txt")

"This line reads the test set's activity labels into a variable"

* SubjTrain <- read.table(".\\train\\subject_train.txt")

"This line reads the label of the subject responsible for an activity in the training set into a variable"

* SubjTest <- read.table(".\\test\\subject_test.txt")

"This line reads the label of the subject responsible for an activity in the test set into a variable"

* Trainset <- cbind(ActTrain,SubjTrain,Trainset)

"This line inserts two columns in the training set. The first containing the activity's label, and the second the subject who performed it. Each row will thus be composed by the Activity, the Subject and the measurements for that condition."

* Testset <- cbind(ActTest,SubjTest,Testset)

"This line inserts two columns in the test set. The first containing the activity's label, and the second the subject who performed it. Each row will thus be composed by the Activity, the Subject and the measurements for that condition."

### Step 1

* superset <- rbind(Testset,Trainset)

"This line creates a dataset containing both the Test and Trainig sets."

### Step 4
* Names <- read.table(".\\features.txt", stringsAsFactors = F)

"This line reads the names of the variables in the superset from the corresponding file in the extracted folder. The option stringsAsFactors was chosen as false to ensure that what is read is stored as strings."

* Names <- Names[,2]

"The file from which the names are read contains two informations. One index and one string with the name for aech variable. So in order to get only the names it is necessary to subset the R variable, getting only the second column, in other words the strings."

* names(superset) <- c("Activity","Subject",Names)

"This line assigns the names read in the previos steps to the dataset variables. In this line also the activities and subject coumns are named."

* rm(ActTest,ActTrain,SubjTest,SubjTrain,Testset,Trainset,Names)

"This line removes R objects that are no longer required. This is a good practice to release memory, which may become scarce if one is dealing with very large datasets."

### Step 2

* Mean <- superset[grep("mean",names(superset))]

"This line extracts the columns from the dataset in which the name indicates a mean. For moreinformation consult the grep function help."

* STD <- superset[grep("std",names(superset))]

"This line extracts the columns from the dataset in which the name indicates a standard deviation. For moreinformation consult the grep function help."

* superset <- cbind(superset\$Activity,superset\$Subject,Mean,STD)

"This line redefines the superset in order to contain only the observations required by Step 2, and the activities and subject information, theat will be required for Step 5."

* names(superset)[1] <- "Activity"

"This line corrects the name of the activity variable in the dataset."

* names(superset)[2] <- "Subject"

"This line corrects the name of the subject variable in the dataset."

* rm(Mean, STD)

"This line gets rid of R object that are no longer required."

### Step 5

* library(plyr)

"This line loads the plyr package. This package is necessary because it contains the function ddply."

* superset <- ddply(superset,.(Activity,Subject),colMeans)

"This line uses the ddply function in conjunction with the colMeans to calculate the columnwise means of all variales in the superset. It also groups the observation by activity and individuals. For more information consult the ddply function help."

### Step 3

* superset\$Activity <- factor(superset\$Activity, label=c("WALKING","WALKING_UPSTAIRS","WALKING_DOWNSTAIRS","SITTING","STANDING","LAYING"))

"In the previous step all the information in the superset was numeric. This is necessary to ddply work properly. 
As Step 3 requests the activities to be named, this line converts the numeric values into factors.
In this case for convenience the labels were inserted by hand, once there are only six of them. If there were more the first two lines of Step 4 could be used to read the labels from the activity_labels.txt file."

### Creating the output file

* write.table(superset,".\\tidyDataSet.txt",row.name = F)

"This line creates the tidyDataSet.txt file as requested."








